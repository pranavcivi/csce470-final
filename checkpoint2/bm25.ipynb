{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\civip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from lyricsgenius import Genius\n",
    "\n",
    "with open('../lyrics-updated.pkl', 'rb') as f:\n",
    "    song_lyrics = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('../classifications.pkl', 'rb') as f1:\n",
    "    classifications = pickle.load(f1)\n",
    "\n",
    "with open('../output/big-songs-updated.pkl', 'rb') as f2:\n",
    "    big_songs = pickle.load(f2)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def tokenize(lyrics):\n",
    "    words = lyrics.lower().split()\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "k1 = 1.0\n",
    "b = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Tears in Heaven\" by Eric Clapton...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# call the api to get the lyrics\n",
    "\n",
    "genius = Genius('HhcPCGMwENzdfMQlauEV1Om0UormkWc6Wrwxri-LFTfBSNkzhwMSVUnR5tZG8eXW')\n",
    "genius.remove_section_headers = True\n",
    "genius.skip_non_songs = False\n",
    "genius.excluded_terms = [\"Remix\", \"Live\"]\n",
    "\n",
    "# song_name = \"Happy\"\n",
    "# artist = \"Pharrel Williams\"\n",
    "# song_name = \"Firework\"\n",
    "# artist = \"Katy Perry\"\n",
    "# song_name = \"I Hate Everything About You\"\n",
    "# artist = \"Three Days Grace\"\n",
    "# song_name = \"Coffee\"\n",
    "# artist = \"Chappell Roan\"\n",
    "song_name = \"Tears in Heaven\"\n",
    "artist = \"Eric Clapton\"\n",
    "\n",
    "\n",
    "song = genius.search_song(song_name, artist)\n",
    "pos = song.lyrics.find(f'{song_name} Lyrics')\n",
    "query = song.lyrics[pos:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tears in heaven lyrics would you know my name if i saw you in heaven would it be the same if i saw you in heaven  i must be strong and carry on cause i know i dont belong here in heaven  would you hold my hand if i saw you in heaven would you help me stand if i saw you in heaven  ill find my way through night and day cause i know i just cant stay here in heaven  time can bring you down time can bend your knees time can break your heart have you begging please begging please you might also like  beyond the door theres peace im sure and i know therell be no more tears in heaven  would you know my name if i saw you in heaven would you be the same if i saw you in heaven  i must be strong and carry on cause i know i dont belong here in heavenembed'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then remove  capital letters and non alphanumeric characters\n",
    "query = query.lower()\n",
    "query = ''.join([char if char.isalpha() or char.isspace() else '' for char in query.replace('\\n', ' ')])\n",
    "# it might seem crazy what im bout to say\n",
    "query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize all documents\n",
    "tokenized_songs = {}\n",
    "for category, all_lyrics in big_songs.items():\n",
    "    tokenized_songs[category] = tokenize(all_lyrics)\n",
    "\n",
    "# calculate document lengths\n",
    "doc_lengths = {}\n",
    "for  category, all_lyrics in tokenized_songs.items():\n",
    "    doc_lengths[category] = len(all_lyrics)\n",
    "\n",
    "# avg doc length\n",
    "avg_doc_length = sum(doc_lengths.values()) / len(doc_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate doc freqs\n",
    "doc_freqs = {}\n",
    "for doc in tokenized_songs.values():\n",
    "    unique_terms = set(doc)\n",
    "    for term in unique_terms:\n",
    "        doc_freqs[term] = doc_freqs.get(term, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25 algorithm\n",
    "def bm25(query, document, doc_length):\n",
    "    score = 0.0\n",
    "    query_terms = tokenize(query)\n",
    "    term_freqs = Counter(document)\n",
    "    \n",
    "    for term in query_terms:\n",
    "        if term in doc_freqs:  # term must appear in the corpus\n",
    "            # Calculate BM25 components\n",
    "            doc_freq = doc_freqs[term]\n",
    "            idf = math.log((len(big_songs) - doc_freq + 0.5) / (doc_freq + 0.5) + 1)\n",
    "            term_freq = term_freqs[term]\n",
    "            term_score = idf * (term_freq * (k1 + 1)) / (term_freq + k1 * (1 - b + b * doc_length / avg_doc_length))\n",
    "            score += term_score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Rankings:\n",
      "Rank 1: Document mild with score 9.0468\n",
      "Rank 2: Document anxious with score 9.0352\n",
      "Rank 3: Document eager with score 8.9053\n",
      "Rank 4: Document lukewarm with score 8.5406\n",
      "Rank 5: Document thrilling with score 7.3612\n",
      "Rank 6: Document excited with score 7.2348\n",
      "Rank 7: Document curious with score 7.0540\n",
      "Rank 8: Document confident with score 7.0420\n",
      "Rank 9: Document electric with score 6.9851\n",
      "Rank 10: Document neutral with score 6.7555\n",
      "Rank 11: Document passionate with score 6.6376\n",
      "Rank 12: Document indifferent with score 6.6092\n",
      "Rank 13: Document enthusiastic with score 6.2190\n",
      "Rank 14: Document animated with score 6.2130\n",
      "Rank 15: Document hectic with score 5.7224\n",
      "Rank 16: Document delightful with score 5.5865\n",
      "Rank 17: Document pleasing with score 5.4591\n",
      "Rank 18: Document fulfilled with score 5.3099\n",
      "Rank 19: Document happy with score 5.2761\n",
      "Rank 20: Document frustration with score 5.2156\n",
      "Rank 21: Document distressed with score 4.9994\n",
      "Rank 22: Document content with score 4.5693\n",
      "Rank 23: Document serious with score 4.3881\n",
      "Rank 24: Document sorrowful with score 4.3758\n",
      "Rank 25: Document determined with score 4.0873\n",
      "Rank 26: Document satisfaction with score 3.7487\n",
      "Rank 27: Document sad with score 2.2816\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for doc_id, doc in tokenized_songs.items():\n",
    "    score = bm25(query, doc, doc_lengths[doc_id])\n",
    "    scores.append((doc_id, score))\n",
    "\n",
    "# Sort documents by score in descending order\n",
    "ranked_docs = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the ranking results\n",
    "print(\"Document Rankings:\")\n",
    "for rank, (doc_id, score) in enumerate(ranked_docs, start=1):\n",
    "    print(f\"Rank {rank}: Document {doc_id} with score {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
