{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\civip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from lyricsgenius import Genius\n",
    "\n",
    "with open('../lyrics-updated.pkl', 'rb') as f:\n",
    "    song_lyrics = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('../classifications.pkl', 'rb') as f1:\n",
    "    classifications = pickle.load(f1)\n",
    "\n",
    "with open('../output/big-songs-updated.pkl', 'rb') as f2:\n",
    "    big_songs = pickle.load(f2)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def tokenize(lyrics):\n",
    "    words = lyrics.lower().split()\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "k1 = 1.0\n",
    "b = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Coffee\" by Chappell Roan...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# call the api to get the lyrics\n",
    "\n",
    "genius = Genius('HhcPCGMwENzdfMQlauEV1Om0UormkWc6Wrwxri-LFTfBSNkzhwMSVUnR5tZG8eXW')\n",
    "genius.remove_section_headers = True\n",
    "genius.skip_non_songs = False\n",
    "genius.excluded_terms = [\"Remix\", \"Live\"]\n",
    "\n",
    "# song_name = \"Happy\"\n",
    "# artist = \"Pharrel Williams\"\n",
    "# song_name = \"Firework\"\n",
    "# artist = \"Katy Perry\"\n",
    "# song_name = \"I Hate Everything About You\"\n",
    "# artist = \"Three Days Grace\"\n",
    "# song_name = \"Coffee\"\n",
    "# artist = \"Chappell Roan\"\n",
    "song_name = \"Boulevard of Broken Dreams\"\n",
    "artist = \"Green Day\"\n",
    "\n",
    "\n",
    "song = genius.search_song(song_name, artist)\n",
    "pos = song.lyrics.find(f'{song_name} Lyrics')\n",
    "query = song.lyrics[pos:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coffee lyrics cant meet you for dinner at the italian place its where i met your family some words were exchanged id suggest the jazz bar on mary ann street but youd buy me a drink\\u205fand\\u205fwe\\u205fknow where that\\u205fleads so  ill meet\\u205fyou for coffee cause if we have wine youll say that you want me i know thats a lie if i didnt love you it would be fine meet you for coffee only for coffee nowhere else is safe every place leads back to your place  you said lets do the park cause i love the park that may be true but god forbid it gets dark here come the excuses that fuel the illusions but id rather feel something than nothing at all so  ill meet you for coffee cause if we have wine youll say that youre sorry i know thats a lie if i didnt trust you it would be fine ill meet you for coffee only for coffee nowhere else is safe every place leads back to your  see chappell roan liveget tickets as low as you might also like weve done this before and i dont need it anymore  so lets not do coffee lets not even try its better we leave it and give it some time if i didnt love you it would be fine cause if we do coffee its never just coffee its never just coffeeembed'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then remove  capital letters and non alphanumeric characters\n",
    "query = query.lower()\n",
    "query = ''.join([char if char.isalpha() or char.isspace() else '' for char in query.replace('\\n', ' ')])\n",
    "# it might seem crazy what im bout to say\n",
    "query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize all documents\n",
    "tokenized_songs = {}\n",
    "for category, all_lyrics in big_songs.items():\n",
    "    tokenized_songs[category] = tokenize(all_lyrics)\n",
    "\n",
    "# calculate document lengths\n",
    "doc_lengths = {}\n",
    "for  category, all_lyrics in tokenized_songs.items():\n",
    "    doc_lengths[category] = len(all_lyrics)\n",
    "\n",
    "# avg doc length\n",
    "avg_doc_length = sum(doc_lengths.values()) / len(doc_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate doc freqs\n",
    "doc_freqs = {}\n",
    "for doc in tokenized_songs.values():\n",
    "    unique_terms = set(doc)\n",
    "    for term in unique_terms:\n",
    "        doc_freqs[term] = doc_freqs.get(term, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25 algorithm\n",
    "def bm25(query, document, doc_length):\n",
    "    score = 0.0\n",
    "    query_terms = tokenize(query)\n",
    "    term_freqs = Counter(document)\n",
    "    \n",
    "    for term in query_terms:\n",
    "        if term in doc_freqs:  # term must appear in the corpus\n",
    "            # Calculate BM25 components\n",
    "            doc_freq = doc_freqs[term]\n",
    "            idf = math.log((len(big_songs) - doc_freq + 0.5) / (doc_freq + 0.5) + 1)\n",
    "            term_freq = term_freqs[term]\n",
    "            term_score = idf * (term_freq * (k1 + 1)) / (term_freq + k1 * (1 - b + b * doc_length / avg_doc_length))\n",
    "            score += term_score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Rankings:\n",
      "Rank 1: Document mild with score 26.3897\n",
      "Rank 2: Document curious with score 23.5736\n",
      "Rank 3: Document pleasing with score 23.3617\n",
      "Rank 4: Document electric with score 21.7011\n",
      "Rank 5: Document hectic with score 21.0720\n",
      "Rank 6: Document fulfilled with score 19.5661\n",
      "Rank 7: Document confident with score 19.4973\n",
      "Rank 8: Document indifferent with score 19.0466\n",
      "Rank 9: Document passionate with score 18.8336\n",
      "Rank 10: Document delightful with score 18.7744\n",
      "Rank 11: Document animated with score 18.1456\n",
      "Rank 12: Document eager with score 15.6551\n",
      "Rank 13: Document enthusiastic with score 15.3123\n",
      "Rank 14: Document determined with score 15.1244\n",
      "Rank 15: Document lukewarm with score 15.1241\n",
      "Rank 16: Document neutral with score 15.0750\n",
      "Rank 17: Document serious with score 14.8654\n",
      "Rank 18: Document thrilling with score 14.1789\n",
      "Rank 19: Document frustration with score 14.0713\n",
      "Rank 20: Document satisfaction with score 14.0211\n",
      "Rank 21: Document excited with score 13.9074\n",
      "Rank 22: Document happy with score 13.5405\n",
      "Rank 23: Document distressed with score 10.4294\n",
      "Rank 24: Document sorrowful with score 9.5809\n",
      "Rank 25: Document anxious with score 8.5331\n",
      "Rank 26: Document content with score 7.7036\n",
      "Rank 27: Document sad with score 3.5104\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for doc_id, doc in tokenized_songs.items():\n",
    "    score = bm25(query, doc, doc_lengths[doc_id])\n",
    "    scores.append((doc_id, score))\n",
    "\n",
    "# Sort documents by score in descending order\n",
    "ranked_docs = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the ranking results\n",
    "print(\"Document Rankings:\")\n",
    "for rank, (doc_id, score) in enumerate(ranked_docs, start=1):\n",
    "    print(f\"Rank {rank}: Document {doc_id} with score {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
